## Project Overview
This project develops an end-to-end, interpretable modeling pipeline for predicting auto insurance losses using a blend of actuarial methods and modern machine learning. The workflow includes data engineering, exploratory analysis, disciplined variable reduction, and systematic model comparison to produce reliable, policy-level loss predictions .

Key steps include engineering core insurance targets (frequency, severity, and pure premium), handling heavy-tailed losses via severity capping, and applying a two-stage variable reduction process combining tree-based screening and VarClusHi clustering to address redundancy and multicollinearity. Multiple model families were evaluated, with a tuned XGBoost Tweedie model achieving the strongest predictive performance relative to actuarial baselines and transformer-based alternatives. The final model was deployed on unseen data with SHAP-based global and local explanations, enabling transparent risk assessment suitable for underwriting and pricing applications.
